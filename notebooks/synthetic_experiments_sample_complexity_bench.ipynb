{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15cfd5b5-ef7d-4ed7-b168-5d76ac0ddc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from collections.abc import Iterator, Mapping\n",
    "from types import MappingProxyType\n",
    "from typing import Any, Literal, Optional\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from ott import datasets\n",
    "from ott.geometry import costs, pointcloud\n",
    "\n",
    "from ott.tools import sinkhorn_divergence\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from ott.geometry.geometry import Geometry\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from ott.geometry import costs, pointcloud\n",
    "from ott.problems.linear import linear_problem, potentials\n",
    "from ott.solvers import linear\n",
    "from ott.tools import progot\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "import importlib\n",
    "import FRLC\n",
    "from FRLC import FRLC_opt\n",
    "import HR_OT\n",
    "importlib.reload(HR_OT)\n",
    "\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a983f260-648f-42b3-a200-40f81c9cd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global n_points;\n",
    "n_points = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7fe440-9ffd-44b8-a187-c5177b7cb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval_samples(\n",
    "    eval_data_source, eval_data_target, transported_samples=None\n",
    "):\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 2, figsize=(8, 4), gridspec_kw={\"wspace\": 0, \"hspace\": 0}\n",
    "    )\n",
    "    axs[0].scatter(\n",
    "        eval_data_source[:, 0],\n",
    "        eval_data_source[:, 1],\n",
    "        color=\"#A7BED3\",\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        label=\"source\",\n",
    "    )\n",
    "    axs[0].set_title(\"Source measure samples\")\n",
    "    axs[1].scatter(\n",
    "        eval_data_target[:, 0],\n",
    "        eval_data_target[:, 1],\n",
    "        color=\"#1A254B\",\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        label=\"target\",\n",
    "    )\n",
    "    axs[1].set_title(\"Target measure samples\")\n",
    "\n",
    "    if transported_samples is not None:\n",
    "        axs[1].scatter(\n",
    "            transported_samples[:, 0],\n",
    "            transported_samples[:, 1],\n",
    "            color=\"#F2545B\",\n",
    "            s=10,\n",
    "            alpha=0.5,\n",
    "            label=\"pushforward of source\",\n",
    "        )\n",
    "\n",
    "    fig.legend(\n",
    "        **{\n",
    "            \"ncol\": (3 if transported_samples is not None else 2),\n",
    "            \"loc\": \"upper center\",\n",
    "            \"bbox_to_anchor\": (0.5, 0.1),\n",
    "            \"edgecolor\": \"k\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class MAFMoonSampler:\n",
    "    size: int\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = jax.random.key(0)\n",
    "        while True:\n",
    "            rng, sample_key = jax.random.split(rng, 2)\n",
    "            yield self._sample(sample_key, self.size)\n",
    "\n",
    "    def _sample(self, key, batch_size):\n",
    "        x = jax.random.normal(key, shape=[batch_size, 2])\n",
    "        x = x.at[:, 0].add(x[:, 1] ** 2)\n",
    "        x = x.at[:, 0].mul(0.5)\n",
    "        x = x.at[:, 0].add(-5)\n",
    "        return x\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class RingSampler:\n",
    "    size: int\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = jax.random.key(0)\n",
    "        while True:\n",
    "            rng, sample_key = jax.random.split(rng, 2)\n",
    "            yield self._sample(sample_key, self.size)\n",
    "\n",
    "    def _sample(self, key, batch_size):\n",
    "        n_samples4 = n_samples3 = n_samples2 = batch_size // 4\n",
    "        n_samples1 = batch_size - n_samples4 - n_samples3 - n_samples2\n",
    "\n",
    "        linspace4 = jnp.linspace(0, 2 * jnp.pi, n_samples4, endpoint=False)\n",
    "        linspace3 = jnp.linspace(0, 2 * jnp.pi, n_samples3, endpoint=False)\n",
    "        linspace2 = jnp.linspace(0, 2 * jnp.pi, n_samples2, endpoint=False)\n",
    "        linspace1 = jnp.linspace(0, 2 * jnp.pi, n_samples1, endpoint=False)\n",
    "\n",
    "        circ4_x = jnp.cos(linspace4) * 1.2\n",
    "        circ4_y = jnp.sin(linspace4) * 1.2\n",
    "        circ3_x = jnp.cos(linspace4) * 0.9\n",
    "        circ3_y = jnp.sin(linspace3) * 0.9\n",
    "        circ2_x = jnp.cos(linspace2) * 0.55\n",
    "        circ2_y = jnp.sin(linspace2) * 0.55\n",
    "        circ1_x = jnp.cos(linspace1) * 0.25\n",
    "        circ1_y = jnp.sin(linspace1) * 0.25\n",
    "\n",
    "        X = (\n",
    "            jnp.vstack(\n",
    "                [\n",
    "                    jnp.hstack([circ4_x, circ3_x, circ2_x, circ1_x]),\n",
    "                    jnp.hstack([circ4_y, circ3_y, circ2_y, circ1_y]),\n",
    "                ]\n",
    "            ).T\n",
    "            * 3.0\n",
    "        )\n",
    "        X = sklearn.utils.shuffle(X)\n",
    "\n",
    "        # Add noise\n",
    "        X = X + jax.random.normal(key, shape=X.shape) * 0.08\n",
    "\n",
    "        return X.astype(\"float32\")\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SklearnDistribution:\n",
    "    name: Literal[\"moon\", \"s_curve\"]\n",
    "    theta_rotation: float = 0.0\n",
    "    mean: Optional[jnp.ndarray] = None\n",
    "    noise: float = 0.01\n",
    "    scale: float = 1.0\n",
    "    batch_size: int = 1024\n",
    "    rng: Optional[jax.Array] = None\n",
    "\n",
    "    def __iter__(self) -> Iterator[jnp.ndarray]:\n",
    "        return self._create_sample_generators()\n",
    "\n",
    "    def _create_sample_generators(self) -> Iterator[jnp.ndarray]:\n",
    "        rng = jax.random.key(0) if self.rng is None else self.rng\n",
    "        rotation = jnp.array(\n",
    "            [\n",
    "                [jnp.cos(self.theta_rotation), -jnp.sin(self.theta_rotation)],\n",
    "                [jnp.sin(self.theta_rotation), jnp.cos(self.theta_rotation)],\n",
    "            ]\n",
    "        )\n",
    "        while True:\n",
    "            rng, _ = jax.random.split(rng)\n",
    "            seed = jax.random.randint(rng, [], minval=0, maxval=1e5).item()\n",
    "            if self.name == \"moon\":\n",
    "                samples, _ = sklearn.datasets.make_moons(\n",
    "                    n_samples=(self.batch_size, 0),\n",
    "                    random_state=seed,\n",
    "                    noise=self.noise,\n",
    "                )\n",
    "            elif self.name == \"s_curve\":\n",
    "                x, _ = sklearn.datasets.make_s_curve(\n",
    "                    n_samples=self.batch_size,\n",
    "                    random_state=seed,\n",
    "                    noise=self.noise,\n",
    "                )\n",
    "                samples = x[:, [2, 0]]\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    f\"SklearnDistribution `{self.name}` not implemented.\"\n",
    "                )\n",
    "\n",
    "            samples = jnp.asarray(samples, dtype=jnp.float32)\n",
    "            samples = jnp.squeeze(jnp.matmul(rotation[None, :], samples.T).T)\n",
    "            mean = jnp.zeros(2) if self.mean is None else self.mean\n",
    "            samples = mean + self.scale * samples\n",
    "            yield samples\n",
    "\n",
    "\n",
    "def create_samplers(\n",
    "    source_kwargs: Mapping[str, Any] = MappingProxyType({}),\n",
    "    target_kwargs: Mapping[str, Any] = MappingProxyType({}),\n",
    "    train_batch_size: int = 512,\n",
    "    valid_batch_size: int = 512,\n",
    "    rng: Optional[jax.Array] = None,\n",
    "):\n",
    "    rng = jax.random.key(0) if rng is None else rng\n",
    "    rng1, rng2, rng3, rng4 = jax.random.split(rng, 4)\n",
    "    train_dataset = datasets.Dataset(\n",
    "        source_iter=iter(\n",
    "            SklearnDistribution(\n",
    "                rng=rng1, batch_size=train_batch_size, **source_kwargs\n",
    "            )\n",
    "        ),\n",
    "        target_iter=iter(\n",
    "            SklearnDistribution(\n",
    "                rng=rng2, batch_size=train_batch_size, **target_kwargs\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    valid_dataset = datasets.Dataset(\n",
    "        source_iter=iter(\n",
    "            SklearnDistribution(\n",
    "                rng=rng3, batch_size=valid_batch_size, **source_kwargs\n",
    "            )\n",
    "        ),\n",
    "        target_iter=iter(\n",
    "            SklearnDistribution(\n",
    "                rng=rng4, batch_size=valid_batch_size, **target_kwargs\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    dim_data = 2\n",
    "    return train_dataset, valid_dataset, dim_data\n",
    "\n",
    "def ret_pts(experiment, n_points = 512):\n",
    "    if experiment == 'checkerboard':\n",
    "    \n",
    "        num_samples_visualize = n_points\n",
    "        (\n",
    "            train_dataloaders,\n",
    "            valid_dataloaders,\n",
    "            input_dim,\n",
    "        ) = datasets.create_gaussian_mixture_samplers(\n",
    "            name_source=\"square_five\",\n",
    "            name_target=\"square_four\",\n",
    "            valid_batch_size=num_samples_visualize,\n",
    "            train_batch_size=2048,\n",
    "        )\n",
    "        \n",
    "        eval_data_source = next(valid_dataloaders.source_iter)\n",
    "        eval_data_target = next(valid_dataloaders.target_iter)\n",
    "        \n",
    "        eval_data_source = next(valid_dataloaders.source_iter)\n",
    "        eval_data_target = next(valid_dataloaders.target_iter)\n",
    "    \n",
    "    elif experiment == 'maf_moon_ring':\n",
    "        \n",
    "        train_loader = datasets.Dataset(\n",
    "        source_iter=iter(MAFMoonSampler(size=n_points)),\n",
    "        target_iter=iter(RingSampler(size=n_points)),\n",
    "        )\n",
    "        valid_loader = train_loader\n",
    "        \n",
    "        eval_data_source = next(train_loader.source_iter)\n",
    "        eval_data_target = next(train_loader.target_iter)\n",
    "    \n",
    "    elif experiment == 'halfmoon_Scurve':\n",
    "    \n",
    "        train_dataset, valid_dataset, dim_data = create_samplers(\n",
    "        source_kwargs={\n",
    "            \"name\": \"moon\",\n",
    "            \"theta_rotation\": jnp.pi / 6,\n",
    "            \"mean\": jnp.array([0.0, -0.5]),\n",
    "            \"noise\": 0.05,\n",
    "        },\n",
    "        target_kwargs={\n",
    "            \"name\": \"s_curve\",\n",
    "            \"scale\": 0.6,\n",
    "            \"mean\": jnp.array([0.5, -2.0]),\n",
    "            \"theta_rotation\": -jnp.pi / 6,\n",
    "            \"noise\": 0.05,\n",
    "            },\n",
    "            train_batch_size=n_points,\n",
    "            valid_batch_size=n_points)\n",
    "        eval_data_source = next(train_dataset.source_iter)\n",
    "        eval_data_target = next(train_dataset.target_iter)\n",
    "\n",
    "    return eval_data_source, eval_data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4183767f-2bc6-46db-afad-28df24da209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On device: cuda\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def sinkhorn_loss(\n",
    "    x: jnp.ndarray, y: jnp.ndarray, epsilon: float = 0.001\n",
    ") -> float:\n",
    "    \"\"\"Computes transport between (x, a) and (y, b) via Sinkhorn algorithm.\"\"\"\n",
    "    a = jnp.ones(len(x)) / len(x)\n",
    "    b = jnp.ones(len(y)) / len(y)\n",
    "    \n",
    "    _, out = sinkhorn_divergence.sinkhorn_divergence(\n",
    "        pointcloud.PointCloud, x, y, epsilon=epsilon, a=a, b=b\n",
    "    )\n",
    "    \n",
    "    return out.divergence\n",
    "\n",
    "\n",
    "def run_progot(\n",
    "    x: jnp.ndarray, y: jnp.ndarray, cost_fn: costs.TICost, **kwargs: Any\n",
    ") -> progot.ProgOTOutput:\n",
    "    geom = pointcloud.PointCloud(x, y, cost_fn=cost_fn)\n",
    "    prob = linear_problem.LinearProblem(geom)\n",
    "    estim = progot.ProgOT(**kwargs)\n",
    "    out = estim(prob)\n",
    "    return out\n",
    "\n",
    "K = 4\n",
    "cost_fn = costs.SqEuclidean()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'On device: {device}')\n",
    "\n",
    "dtype = torch.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c068efd8-be5f-461f-b840-96e376ecb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proj(P):\n",
    "    \n",
    "    if isinstance(P, torch.Tensor):\n",
    "        P = P.cpu().numpy()\n",
    "    \n",
    "    opt_target = np.diag(1 / np.sum(P, axis=1)) @ P @ Y\n",
    "    for idx1 in range(P.shape[0]):\n",
    "        x_values = X[idx1, 0], opt_target[idx1, 0]\n",
    "        y_values = X[idx1, 1], opt_target[idx1, 1]\n",
    "        plt.plot(x_values, y_values, c='black', linewidth=0.8, alpha=0.8)\n",
    "    \n",
    "    plt.scatter(X[:, 0], X[:, 1], c='b', label='Initial Points (Source)', alpha=0.7)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c='r', label='Final Points (Target)', alpha=0.7)\n",
    "    plt.scatter(opt_target[:, 0], opt_target[:, 1], c='gold', label='Optimal Map', alpha=0.7)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c382516-38e1-4567-a380-fc8035dec5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(HR_OT)\n",
    "import objective_grad\n",
    "import util\n",
    "importlib.reload(FRLC)\n",
    "importlib.reload(objective_grad)\n",
    "importlib.reload(util)\n",
    "\n",
    "sample_sizes = [int(2**i) for i in range(5, 18, 1)]\n",
    "\n",
    "experiment = 'halfmoon_Scurve' #'checkerboard'#'halfmoon_Scurve' #'maf_moon_ring'\n",
    "plot_pts =  False\n",
    "\n",
    "cost_list_hrot = []\n",
    "cost_list_hrot_lr = []\n",
    "cost_list_sinkhorn = []\n",
    "cost_list_progOT = []\n",
    "\n",
    "# Squared Euclidean cost p=2 or Euclidean if p=1\n",
    "p = 1\n",
    "K = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "128e3693-3824-4b5c-990c-d5f1ddb8512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-01-24 18:54:03,551:jax._src.xla_bridge:987: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sample size: 32\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 75\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 75\n",
      "Iteration: 100\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Current Costs:\n",
      "  HROT: 2.2180542945861816\n",
      "  HROT_LR: 2.2231879234313965\n",
      "  Sinkhorn: 2.2296245098114014\n",
      "  ProgOT: 2.236151933670044\n",
      "Current sample size: 64\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 75\n",
      "Iteration: 100\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 75\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 75\n",
      "Iteration: 100\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_sizes = [int(2**i) for i in range(5, 18, 1)]\n",
    "\n",
    "# Initialize dictionaries to store costs and sample sizes\n",
    "costs = {\n",
    "    'HROT': {'samples': [], 'costs': []},\n",
    "    'HROT_LR': {'samples': [], 'costs': []},\n",
    "    'Sinkhorn': {'samples': [], 'costs': []},\n",
    "    'ProgOT': {'samples': [], 'costs': []}\n",
    "}\n",
    "\n",
    "for n in sample_sizes:\n",
    "    print(f'Current sample size: {n}')\n",
    "    X, Y = ret_pts(experiment, n_points=n)\n",
    "    # Define pairwise Dist Mat\n",
    "    _X = torch.tensor(np.array(X)).float().to(device)\n",
    "    _Y = torch.tensor(np.array(Y)).float().to(device)\n",
    "    rank_schedule = [K, int(n / K)]  # Total of (1+K) runs of low-rank OT req'd\n",
    "    \n",
    "    try:\n",
    "        hrot_lr = HR_OT.HierarchicalRefinementOT.init_from_point_clouds(_X, _Y, rank_schedule, base_rank=1, device=device)\n",
    "        F = hrot_lr.run(return_as_coupling=False)\n",
    "        cost_hrot_lr = hrot_lr.compute_OT_cost()\n",
    "        costs['HROT_LR']['samples'].append(n)\n",
    "        costs['HROT_LR']['costs'].append(cost_hrot_lr.item())\n",
    "    except Exception as e:\n",
    "        print(f'HROT-LR failed for sample size {n}: {e}')\n",
    "    \n",
    "    try:\n",
    "        C = torch.cdist(_X, _Y) ** p\n",
    "    except Exception as e:\n",
    "        print(f'Failed to load cost mat for sample size {n}: {e}')\n",
    "        continue\n",
    "\n",
    "    # HROT \n",
    "    try:\n",
    "        hrot = HR_OT.HierarchicalRefinementOT(C, rank_schedule, base_rank=1, device=device)\n",
    "        F = hrot.run(return_as_coupling=False)\n",
    "        cost_hrot = hrot.compute_OT_cost()\n",
    "        costs['HROT']['samples'].append(n)\n",
    "        costs['HROT']['costs'].append(cost_hrot.item())\n",
    "    except Exception as e:\n",
    "        print(f'HROT failed for sample size {n}: {e}')\n",
    "\n",
    "    # Sinkhorn \n",
    "    try:\n",
    "        geom = Geometry(C.cpu().numpy())\n",
    "        ot_problem = linear_problem.LinearProblem(geom)\n",
    "        solver = sinkhorn.Sinkhorn()\n",
    "        ot_solution = solver(ot_problem)\n",
    "        P_sinkhorn = ot_solution.matrix\n",
    "        cost_sink = (C.cpu().numpy() * P_sinkhorn).sum()\n",
    "        costs['Sinkhorn']['samples'].append(n)\n",
    "        costs['Sinkhorn']['costs'].append(cost_sink)\n",
    "    except Exception as e:\n",
    "        print(f'Sinkhorn failed for sample size {n}: {e}')\n",
    "\n",
    "    # ProgOT \n",
    "    try:\n",
    "        x_train, y_train = X, Y\n",
    "        alphas = progot.get_alpha_schedule(\"exp\", num_steps=K)\n",
    "        out = run_progot(X, Y, cost_fn, alphas=alphas, epsilons=None)\n",
    "        P_progOT_default = out.get_output(-1).matrix\n",
    "        cost_progOT = (C.cpu().numpy() * P_progOT_default).sum()\n",
    "        costs['ProgOT']['samples'].append(n)\n",
    "        costs['ProgOT']['costs'].append(cost_progOT)\n",
    "    except Exception as e:\n",
    "        print(f'ProgOT failed for sample size {n}: {e}')\n",
    "\n",
    "    # Optionally, print the costs for successful methods\n",
    "    print(\"Current Costs:\")\n",
    "    for method in costs:\n",
    "        if costs[method]['samples'] and costs[method]['samples'][-1] == n:\n",
    "            print(f\"  {method}: {costs[method]['costs'][-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a6dca-f919-4865-ae62-a2b836fbdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for method, data in costs.items():\n",
    "    if data['samples']:\n",
    "        plt.plot(data['samples'], data['costs'], marker='o', label=method)\n",
    "\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Method Costs over Sample Complexities')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed956b2-34cd-4511-9434-871604019cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for n in sample_sizes:\n",
    "    \n",
    "    print(f'Current sample size: {n}')\n",
    "    \n",
    "    X, Y = ret_pts(experiment, n_points = n)\n",
    "    \n",
    "    # Define pairwise Dist Mat\n",
    "    _X, _Y = torch.tensor(np.array(X)).type(torch.DoubleTensor).to(device), \\\n",
    "                        torch.tensor(np.array(Y)).type(torch.DoubleTensor).to(device)\n",
    "    C = torch.cdist( _X, _Y ) ** p\n",
    "    rank_schedule = [ K, int( n / K ) ] # Total of (1+K) runs of low-rank OT req'd\n",
    "    \n",
    "    # Full-rank cost matrix\n",
    "    hrot = HR_OT.HierarchicalRefinementOT(C, \\\n",
    "                                  rank_schedule, \\\n",
    "                                  base_rank=1)\n",
    "    P = hrot.run(return_as_coupling=True)\n",
    "    cost_hrot = hrot.compute_OT_cost()\n",
    "    cost_list_hrot.append(cost_hrot)\n",
    "    #plot_proj(P)\n",
    "\n",
    "    # Low-rank cost matrix\n",
    "    hrot_lr = HR_OT.HierarchicalRefinementOT.init_from_point_clouds(_X, _Y, \\\n",
    "                                  rank_schedule, base_rank=1)\n",
    "    P = hrot_lr.run(return_as_coupling=True)\n",
    "    #plot_proj(P)\n",
    "    cost_hrot_lr = hrot_lr.compute_OT_cost()\n",
    "    cost_list_hrot_lr.append(cost_hrot_lr)\n",
    "    \n",
    "    #Sinkhorn Sol'n\n",
    "    geom = Geometry( C.cpu().numpy() )\n",
    "    ot_problem = linear_problem.LinearProblem(geom)\n",
    "    solver = sinkhorn.Sinkhorn()\n",
    "    ot_solution = solver(ot_problem)\n",
    "    P_sinkhorn = ot_solution.matrix\n",
    "    #plot_proj(np.array(P_sinkhorn))\n",
    "    cost_sink = ( C.cpu().numpy() * P_sinkhorn ).sum()\n",
    "    cost_list_sink.append(cost_sink)\n",
    "\n",
    "    # ProgOT Sol'n\n",
    "    x_train, y_train = X, Y\n",
    "    alphas = progot.get_alpha_schedule(\"exp\", num_steps=K)\n",
    "    out = run_progot(X, Y, \\\n",
    "                     cost_fn, alphas=alphas, \\\n",
    "                     epsilons=None)\n",
    "    P_progOT_default = out.get_output(-1).matrix\n",
    "    #plot_proj(np.array(P_progOT_default))\n",
    "    cost_progOT = ( C.cpu().numpy() * P_progOT_default ).sum()\n",
    "    cost_list_progOT.append(cost_progOT)\n",
    "    \n",
    "    print(f'cost HROT: { cost_hrot.item() }, cost HROT-LR: { cost_hrot_lr.item() \\\n",
    "                                                }, cost Sink: { cost_sink }, cost progOT: { cost_progOT }')\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peterenv2 [~/.conda/envs/peterenv2/]",
   "language": "python",
   "name": "conda_peterenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
