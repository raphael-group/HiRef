{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfd5b5-ef7d-4ed7-b168-5d76ac0ddc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from collections.abc import Iterator, Mapping\n",
    "from types import MappingProxyType\n",
    "from typing import Any, Literal, Optional\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from ott import datasets\n",
    "from ott.geometry import costs, pointcloud\n",
    "\n",
    "from ott.tools import sinkhorn_divergence\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from ott.geometry.geometry import Geometry\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from ott.geometry import costs, pointcloud\n",
    "from ott.problems.linear import linear_problem, potentials\n",
    "from ott.solvers import linear\n",
    "from ott.tools import progot\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "import importlib\n",
    "import FRLC\n",
    "from FRLC import FRLC_opt\n",
    "import HR_OT\n",
    "importlib.reload(HR_OT)\n",
    "\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4183767f-2bc6-46db-afad-28df24da209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On device: cpu\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def sinkhorn_loss(\n",
    "    x: jnp.ndarray, y: jnp.ndarray, epsilon: float = 0.001\n",
    ") -> float:\n",
    "    \"\"\"Computes transport between (x, a) and (y, b) via Sinkhorn algorithm.\"\"\"\n",
    "    a = jnp.ones(len(x)) / len(x)\n",
    "    b = jnp.ones(len(y)) / len(y)\n",
    "    \n",
    "    _, out = sinkhorn_divergence.sinkhorn_divergence(\n",
    "        pointcloud.PointCloud, x, y, epsilon=epsilon, a=a, b=b\n",
    "    )\n",
    "    \n",
    "    return out.divergence\n",
    "\n",
    "\n",
    "def run_progot(\n",
    "    x: jnp.ndarray, y: jnp.ndarray, cost_fn: costs.TICost, **kwargs: Any\n",
    ") -> progot.ProgOTOutput:\n",
    "    geom = pointcloud.PointCloud(x, y, cost_fn=cost_fn)\n",
    "    prob = linear_problem.LinearProblem(geom)\n",
    "    estim = progot.ProgOT(**kwargs)\n",
    "    out = estim(prob)\n",
    "    return out\n",
    "\n",
    "K = 4\n",
    "cost_fn = costs.SqEuclidean()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'On device: {device}')\n",
    "\n",
    "dtype = torch.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0c6726-c9f4-468c-a814-7d2f3d9c4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d250f60a-f4f5-40a8-90ff-cb959833f50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1281167 images from ImageNet!\n"
     ]
    }
   ],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images for CNN input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load ImageNet dataset from extracted path # /ILSVRC/Data/CLS-LOC/test\n",
    "imagenet_dataset = datasets.ImageFolder(root=\"/scratch/gpfs/DATASETS/imagenet/ilsvrc_2012_classification_localization/train\",\n",
    "                                        transform=transform)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "imagenet_loader = DataLoader(imagenet_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Loaded {len(imagenet_dataset)} images from ImageNet!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9e88f-f745-453f-93f6-ca0c7722bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.cache/torch/hub/checkpoints\n",
    "!mv /home/ph3641/HierarchicalRefinement/HR_OT/HR_OT/notebooks/resnet50-0676ba61.pth ~/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95817aeb-ff44-4b43-8c2c-80adfeb3448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.expanduser(\"~/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\")\n",
    "\n",
    "# Load pretrained ResNet model\n",
    "model = models.resnet50()\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fc = torch.nn.Identity()  # Remove classification layer to extract features\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Compute embeddings\n",
    "def extract_features(dataloader, model):\n",
    "    embeddings = []\n",
    "    num_img = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(dataloader):\n",
    "            num_img += len(images)\n",
    "            if idx % 100 == 0:\n",
    "                print(f'image idx {idx}, images: {num_img}')\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            embeddings.append(features.cpu().numpy())\n",
    "    return np.vstack(embeddings)  # Stack all embeddings\n",
    "\n",
    "print('extracting embeddings!')\n",
    "embeddings = extract_features(imagenet_loader, model)\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca2fc9-954e-4a85-8d97-b5b07391f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_dir = \"/scratch/gpfs/ph3641/hr_ot/\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, \"embeddings.pkl\")\n",
    "\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(f\"Embeddings saved successfully to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc52a1a1-fd78-4c8a-a084-5b97d2fe468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully! Shape: (1281167, 2048)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "emb_dir = '/scratch/gpfs/ph3641/hr_ot/embeddings.pkl'\n",
    "\n",
    "# Load embeddings from the pickle file\n",
    "with open(emb_dir, \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(f\"Embeddings loaded successfully! Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96da85a1-2329-417e-a7ca-1cbce5a4cd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num embeddings: 1281166\n",
      "Optimized rank-annealing schedule: [7, 50, 1830]\n"
     ]
    }
   ],
   "source": [
    "import rank_annealing\n",
    "\n",
    "# 1. Making it even, remove 1 image\n",
    "embeddings = embeddings[1:,:]\n",
    "\n",
    "# 2. Get to a close even number which when divided is non-prime\n",
    "print(f'num embeddings: {embeddings.shape[0]}')\n",
    "N = embeddings.shape[0] // 2\n",
    "q = 640500\n",
    "k = (N-q)*2\n",
    "\n",
    "embed_sliced = embeddings[:-k]\n",
    "n = embed_sliced.shape[0] // 2\n",
    "\n",
    "rank_schedule = rank_annealing.optimal_rank_schedule( n , hierarchy_depth = 6, max_Q = int(2**11), max_rank = 64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b5469a-3ca0-4cf8-86e2-977d2b6d2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (640500, 2048), Y shape: (640500, 2048)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_samples = embed_sliced.shape[0]\n",
    "\n",
    "# Shuffle indices\n",
    "indices = torch.randperm(num_samples)\n",
    "\n",
    "# Split into two tensors\n",
    "X = embeddings[indices[:n]]  # First 50%\n",
    "Y = embeddings[indices[n:]]  # Second 50%\n",
    "\n",
    "del embeddings, indices, embed_sliced\n",
    "\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128e3693-3824-4b5c-990c-d5f1ddb8512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch Sinkhorn: 100%|██████████| 5004/5004 [03:20<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Mini-batch cost for batch size B = 128: <C,P> = 21.889437173100873-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch Sinkhorn: 100%|██████████| 2502/2502 [03:48<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Mini-batch cost for batch size B = 256: <C,P> = 21.11325375353404-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch Sinkhorn: 100%|██████████| 1251/1251 [07:04<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Mini-batch cost for batch size B = 512: <C,P> = 20.335602532378395-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mini-batch Sinkhorn: 100%|██████████| 626/626 [18:20<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Mini-batch cost for batch size B = 1024: <C,P> = 19.585924760983012-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import functools\n",
    "import operator\n",
    "import rank_annealing\n",
    "import validation\n",
    "importlib.reload(rank_annealing)\n",
    "importlib.reload(HR_OT)\n",
    "\n",
    "# Squared Euclidean cost p=2 or Euclidean if p=1\n",
    "p = 1\n",
    "K = 2\n",
    "\n",
    "# Initialize dictionaries to store costs and sample sizes\n",
    "costs = {\n",
    "    'HROT_LR': {'samples': [], 'costs': []},\n",
    "    'Sinkhorn': {'samples': [], 'costs': []},\n",
    "    'ProgOT': {'samples': [], 'costs': []}\n",
    "}\n",
    "\n",
    "X, Y = np.array(X).astype(np.float32), np.array(Y).astype(np.float32)\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "\n",
    "for B in batch_sizes:\n",
    "    cost = validation.minibatch_sinkhorn_ot_without_replacement(X, Y, B)\n",
    "    print(f'-----Mini-batch cost for batch size B = {B}: <C,P> = {cost}-----')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peterenv2 [~/.conda/envs/peterenv2/]",
   "language": "python",
   "name": "conda_peterenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
